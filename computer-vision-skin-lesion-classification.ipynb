{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# $\\text{HAM10000: } >81\\% \\text{ Accuracy with Custom Hybrid CNN (From Scratch)}$\n\n### $\\textbf{1. Executive Summary}$\n$\\text{This notebook implements a custom \\textbf{Hybrid CNN} trained from scratch to detect skin lesions in the HAM10000 dataset.}$\n$\\text{Unlike standard transfer learning approaches (e.g., ResNet, EfficientNet), this model is architected specifically to solve}$\n$\\text{\\textbf{spatial overfitting} and \\textbf{class imbalance} without pre-trained weights.}$\n\n$\\text{Final Test Accuracy: } \\mathbf{81.50\\%} \\text{ (Strict } 15\\% \\text{ Hold-out Set)}$\n\n---\n\n### $\\textbf{2. Key Technical Contributions}$\n* $\\textbf{Adaptive Pooling Architecture: } \\text{Replaced standard Flatten layers with } \\texttt{AdaptiveAvgPool2d((4, 4))}.$\n    $\\text{This forces the model to learn robust features rather than memorizing spatial pixel locations.}$\n* $\\textbf{Metadata Fusion: } \\text{Integrated clinical features (Age, Sex, Anatomical Site) directly into the Fully Connected layers,}$\n    $\\text{mimicking the dermatological \\textit{ABCD} diagnostic process.}$\n* $\\textbf{Strategic Regularization: } \\text{Enforced sparsity via } \\texttt{AdamW} \\text{ weight decay } (1e^{-4}) \\text{ and } \\texttt{Dropout} \\ (p=0.5),$\n    $\\text{preventing neuron co-adaptation and ensuring generalization on rare classes.}$\n* $\\textbf{Manifold Expansion: } \\text{Utilized } \\texttt{RandomRotation(360)} \\text{ to generate mathematically distinct views of}$\n    $\\text{the minority classes, significantly boosting Recall for \\textit{Dermatofibroma} and \\textit{Vascular} lesions.}$\n\n---\n\n### $\\textbf{3. Methodology Pipeline}$\n1.  $\\textbf{Preprocessing: } \\text{Standardization of metadata; One-Hot Encoding for categorical features.}$\n2.  $\\textbf{Sampling: } \\texttt{WeightedRandomSampler} \\text{ used to inversely weight the loss function against class frequency.}$\n3.  $\\textbf{Augmentation: } \\text{Aggressive geometric transformations (} 360^{\\circ} \\text{ rotation, affine) combined with conservative}$\n    $\\text{color jitter to preserve clinical color semantics.}$\n4.  $\\textbf{Optimization: } \\text{AdamW optimizer with } \\texttt{ReduceLROnPlateau} \\text{ scheduler to navigate the loss landscape efficiently.}$","metadata":{"execution":{"iopub.status.busy":"2025-12-31T13:36:39.093821Z","iopub.execute_input":"2025-12-31T13:36:39.094203Z","iopub.status.idle":"2025-12-31T13:36:39.104117Z","shell.execute_reply.started":"2025-12-31T13:36:39.094174Z","shell.execute_reply":"2025-12-31T13:36:39.102930Z"},"_kg_hide-output":true}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#importing all the libraries\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport glob\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom torch.utils.data import WeightedRandomSampler\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T13:51:07.661861Z","iopub.execute_input":"2025-12-30T13:51:07.662619Z","iopub.status.idle":"2025-12-30T13:51:07.667669Z","shell.execute_reply.started":"2025-12-30T13:51:07.662583Z","shell.execute_reply":"2025-12-30T13:51:07.666837Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nimport numpy as np\nimport torch\n\ndef set_seed(seed=42):\n    \"\"\"Sets the seed for reproducibility across all libraries.\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n\nset_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T13:51:07.669036Z","iopub.execute_input":"2025-12-30T13:51:07.669425Z","iopub.status.idle":"2025-12-30T13:51:07.683902Z","shell.execute_reply.started":"2025-12-30T13:51:07.669401Z","shell.execute_reply":"2025-12-30T13:51:07.683318Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start_meta = pd.read_csv(\"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv\")\n\n#start_meta = start_meta.drop(columns=['dx_type'])\nstart_meta['age'] = start_meta['age'].fillna(start_meta['age'].mean())\n\nscaler = StandardScaler()\nstart_meta['age'] = scaler.fit_transform(start_meta[['age']])\n\nencoder = OneHotEncoder(sparse_output=False) \ncat_cols = ['sex', 'localization']\nencoded_data_numpy = encoder.fit_transform(start_meta[cat_cols])\nfeature_names = encoder.get_feature_names_out(cat_cols)\nencoded_data = pd.DataFrame(encoded_data_numpy, columns=feature_names, index=start_meta.index)\n\nmeta = pd.concat([start_meta[['lesion_id', 'image_id', 'dx', 'age']], encoded_data], axis=1)\n\nunique_lesion_ids = meta['lesion_id'].unique()\n\ntrain_ids, temp_ids = train_test_split(unique_lesion_ids, test_size=0.3, random_state=42)\ntest_ids, validation_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)\n\ntrain_meta = meta[meta['lesion_id'].isin(train_ids)]\ntest_meta = meta[meta['lesion_id'].isin(test_ids)]\nvalidation_meta = meta[meta['lesion_id'].isin(validation_ids)]\n\nprint(f\"train ({100 * len(train_meta) / (len(train_meta) + len(test_meta) + len(validation_meta))}%):\\n{train_meta.head()}\\n\")\nprint(f\"test ({100 * len(test_meta) / (len(train_meta) + len(test_meta) + len(validation_meta))}%):\\n{test_meta.head()}\\n\")\nprint(f\"validation ({100 * len(validation_meta) / (len(train_meta) + len(test_meta) + len(validation_meta))}%):\\n{validation_meta.head()}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T13:51:07.684627Z","iopub.execute_input":"2025-12-30T13:51:07.684930Z","iopub.status.idle":"2025-12-30T13:51:07.748485Z","shell.execute_reply.started":"2025-12-30T13:51:07.684904Z","shell.execute_reply":"2025-12-30T13:51:07.747732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SkinCancerDataset(Dataset):\n    def __init__(self, dataframe, dir_part1, dir_part2, transform = None):\n        self.annotation = dataframe\n        self.dir_part1 = dir_part1\n        self.dir_part2 = dir_part2\n        self.transform = transform\n        self.label_map = {\n             'akiec': 0, \n             'bcc': 1, \n             'bkl': 2, \n             'df': 3, \n             'mel': 4, \n             'nv': 5, \n             'vasc': 6}\n        self.meta_data_cols = self.annotation.drop(columns=[\n            'lesion_id',\n            'image_id',\n            'dx'])\n        \n    def __len__(self):\n        return len(self.annotation)\n\n    def __getitem__(self, index):\n        img_id = self.annotation.iloc[index]['image_id']#ImageID on column 2\n\n        path_part1 = os.path.join(self.dir_part1, img_id + '.jpg')\n        path_part2 = os.path.join(self.dir_part2, img_id + '.jpg')\n        if os.path.exists(path_part1):\n            img_name = path_part1\n        elif os.path.exists(path_part2):\n            img_name = path_part2\n        else:\n            raise FileNotFoundError(f\"Image {img_id} not found in part1 or part2\")\n            \n        image = Image.open(img_name).convert('RGB')\n        \n        label_text = self.annotation.iloc[index]['dx']\n        y_label = torch.tensor(self.label_map[label_text])\n\n        meta_data = self.meta_data_cols.iloc[index].values.astype('float32')\n        meta_data = torch.tensor(meta_data, dtype=torch.float32)\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, y_label, meta_data\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T13:51:07.749232Z","iopub.execute_input":"2025-12-30T13:51:07.749491Z","iopub.status.idle":"2025-12-30T13:51:07.756051Z","shell.execute_reply.started":"2025-12-30T13:51:07.749469Z","shell.execute_reply":"2025-12-30T13:51:07.755494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import transforms\n\n# Training transforms (Randomness added)\ntrain_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),       \n    transforms.RandomHorizontalFlip(),   \n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(360),\n    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0),\n    transforms.ToTensor(),    \n    transforms.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n    transforms.Normalize(                # Standardizes to ImageNet distribution\n        mean=[0.485, 0.456, 0.406], \n        std=[0.229, 0.224, 0.225]\n    )\n])\n\n# Validation transforms (No Randomness, just resizing)\nval_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T13:51:07.757652Z","iopub.execute_input":"2025-12-30T13:51:07.757926Z","iopub.status.idle":"2025-12-30T13:51:07.770920Z","shell.execute_reply.started":"2025-12-30T13:51:07.757910Z","shell.execute_reply":"2025-12-30T13:51:07.770231Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_device():\n    if torch.cuda.is_available():\n        return torch.device(\"cuda\")\n    \n    elif torch.backends.mps.is_available():\n        return torch.device(\"mps\")\n    \n    else:\n        return torch.device(\"cpu\")\n\n\ndevice = get_device()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T13:51:07.771519Z","iopub.execute_input":"2025-12-30T13:51:07.771744Z","iopub.status.idle":"2025-12-30T13:51:07.786615Z","shell.execute_reply.started":"2025-12-30T13:51:07.771730Z","shell.execute_reply":"2025-12-30T13:51:07.785975Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DoubleConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n\n    def forward(self, x):\n        x = F.leaky_relu(self.bn1(self.conv1(x)))\n        x = F.leaky_relu(self.bn2(self.conv2(x)))\n        x = self.pool(x)\n        return x\n        \n\nclass SkinCancerCNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        #feature extraction\n        self.block1 = DoubleConvBlock(3, 32)\n        self.block2 = DoubleConvBlock(32, 64)\n        self.block3 = DoubleConvBlock(64, 128)\n        self.block4 = DoubleConvBlock(128, 256)\n        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n        \n        self.flatten_size = 256 * 4 * 4\n        \n        # First fully connected layer\n        self.fc1 = nn.Linear(self.flatten_size, 128)\n        self.bn3 = nn.BatchNorm1d(128)\n        self.dropout = nn.Dropout(0.5)\n        # Second fully connected layer \n        self.fc2 = nn.Linear(128 + 19, 7)\n\n    def forward(self, x, meta):\n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        x = self.block4(x)\n\n        x = self.adaptive_pool(x)\n        \n        #flatten the data\n        x = x.view(-1, self.flatten_size)\n        #FC layers\n        x = F.leaky_relu(self.bn3(self.fc1(x)))\n        x = self.dropout(x)\n\n        combined = torch.cat((x, meta), dim=1)\n        \n        x = self.fc2(combined)\n\n        return x\n\nskinCancerCNN = SkinCancerCNN()\nprint(skinCancerCNN)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T13:51:07.787311Z","iopub.execute_input":"2025-12-30T13:51:07.787548Z","iopub.status.idle":"2025-12-30T13:51:07.816498Z","shell.execute_reply.started":"2025-12-30T13:51:07.787530Z","shell.execute_reply":"2025-12-30T13:51:07.815769Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(weight=None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T13:51:07.817250Z","iopub.execute_input":"2025-12-30T13:51:07.817487Z","iopub.status.idle":"2025-12-30T13:51:07.821511Z","shell.execute_reply.started":"2025-12-30T13:51:07.817466Z","shell.execute_reply":"2025-12-30T13:51:07.820926Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"learning_rate = 0.0003\n\noptimizer = torch.optim.AdamW(skinCancerCNN.parameters(), learning_rate, weight_decay=1e-4)\n\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=7)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T13:51:07.822164Z","iopub.execute_input":"2025-12-30T13:51:07.822393Z","iopub.status.idle":"2025-12-30T13:51:07.832512Z","shell.execute_reply.started":"2025-12-30T13:51:07.822374Z","shell.execute_reply":"2025-12-30T13:51:07.831972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define your paths (Adjust these to match your specific Kaggle input structure)\ndir_1 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1/\"\ndir_2 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2/\"\n\n# Create Datasets passing BOTH directories\ntrain_dataset = SkinCancerDataset(train_meta, dir_1, dir_2, transform=train_transforms)\nval_dataset = SkinCancerDataset(validation_meta, dir_1, dir_2, transform=val_transforms)\ntest_dataset = SkinCancerDataset(test_meta, dir_1, dir_2, transform=val_transforms)\n\nlabel_map = {\n    'akiec': 0,\n    'bcc' : 1,\n    'bkl' : 2,\n    'df' : 3,\n    'mel' : 4,\n    'nv' : 5,\n    'vasc' : 6,\n}\n\n#create sampler weights\nlabels, counts = np.unique(meta['dx'], return_counts=True)\nweights = 1.0 / np.sqrt(counts) \nweights = weights / weights.sum() * len(counts)\n\nprint(labels, label_map)\n\nsample_weights = [weights[label_map[label]] for label in train_meta['dx']]\n\ng = torch.Generator()\ng.manual_seed(42)\n\nsampler = WeightedRandomSampler(weights=sample_weights,\n                                num_samples=len(sample_weights),\n                                replacement=True,\n                                generator=g)\n\n# Create DataLoaders\ntrain_loader = torch.utils.data.DataLoader(train_dataset,\n                                           batch_size=32,\n                                           sampler=sampler)\n\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T13:51:07.833221Z","iopub.execute_input":"2025-12-30T13:51:07.833488Z","iopub.status.idle":"2025-12-30T13:51:07.853721Z","shell.execute_reply.started":"2025-12-30T13:51:07.833472Z","shell.execute_reply":"2025-12-30T13:51:07.852950Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nfrom tqdm import tqdm # Library for progress bars\nimport matplotlib.pyplot as plt\n\n# ==========================================\n# CONFIGURATION\n# ==========================================\npatience = 20        # How many epochs to wait before stopping if no improvement\nmin_delta = 0.0005   # Minimum change to qualify as an improvement\nearly_stop_counter = 0\nbest_val_loss = float('inf')\nnum_epochs = 100\n\n# Move model to device\nmodel = skinCancerCNN.to(device)\n\n# History storage\nhistory = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n\nprint(f\" Starting training on {device} with Early Stopping...\")\n\n# ==========================================\n# TRAINING LOOP\n# ==========================================\nfor epoch in range(num_epochs):\n    \n    # --- 1. Training Phase ---\n    model.train()\n    running_loss = 0.0\n    \n    # Wrap train_loader with tqdm for a progress bar\n    # 'desc' sets the text before the bar\n    loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\", leave=False)\n    \n    for images, labels, meta_data in loop:\n        images, labels, meta_data = images.to(device), labels.to(device), meta_data.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images, meta_data)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * images.size(0)\n        \n        # Update progress bar with current loss\n        loop.set_postfix(loss=loss.item())\n\n    epoch_loss = running_loss / len(train_loader.dataset)\n    history['train_loss'].append(epoch_loss)\n\n    # --- 2. Validation Phase ---\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for images, labels, meta_data in val_loader:\n            images, labels, meta_data = images.to(device), labels.to(device), meta_data.to(device)\n            outputs = model(images, meta_data)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item() * images.size(0)\n            \n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n    epoch_val_loss = val_loss / len(val_loader.dataset)\n    epoch_acc = 100 * correct / total\n    \n    history['val_loss'].append(epoch_val_loss)\n    history['val_acc'].append(epoch_acc)\n    scheduler.step(epoch_val_loss)\n    current_lr = optimizer.param_groups[0]['lr']\n\n    # Print Clean Stats\n    print(f\"Epoch [{epoch+1}/{num_epochs}]  \"\n          f\"Train Loss: {epoch_loss:.4f} | \"\n          f\"Val Loss: {epoch_val_loss:.4f} | \"\n          f\"Val Acc: {epoch_acc:.2f}% | \"\n          f\"Learning Rate: {current_lr:.6f}\")\n\n    # ==========================================\n    # EARLY STOPPING LOGIC\n    # ==========================================\n    # Check if this validation loss is the best we've seen\n    if epoch_val_loss < (best_val_loss - min_delta):\n        best_val_loss = epoch_val_loss\n        early_stop_counter = 0 # Reset counter\n        torch.save(model.state_dict(), 'best_skin_cancer_model.pth')\n        print(f\"    Validation Loss Improved. Model Saved\")\n    else:\n        early_stop_counter += 1\n        print(f\"    No improvement for {early_stop_counter}/{patience} epochs.\")\n        \n    if early_stop_counter >= patience:\n        print(f\"\\n Early Stopping Triggered! Training stopped at Epoch {epoch+1}.\")\n        break\n\nprint(\"Training Finished.\")\n\n# ==========================================\n# VISUALIZATION\n# ==========================================\ndef plot_training_history(history):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n\n    # Plot Loss\n    ax1.plot(history['train_loss'], label='Train Loss')\n    ax1.plot(history['val_loss'], label='Val Loss')\n    ax1.set_title('Loss History')\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Loss')\n    ax1.legend()\n    ax1.grid(True)\n\n    # Plot Accuracy\n    ax2.plot(history['val_acc'], label='Val Accuracy', color='green')\n    ax2.set_title('Validation Accuracy')\n    ax2.set_xlabel('Epoch')\n    ax2.set_ylabel('Accuracy (%)')\n    ax2.legend()\n    ax2.grid(True)\n\n    plt.show()\n\n# Run the plot\nplot_training_history(history)      \n       ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T13:51:07.854512Z","iopub.execute_input":"2025-12-30T13:51:07.854811Z","iopub.status.idle":"2025-12-30T16:53:40.781954Z","shell.execute_reply.started":"2025-12-30T13:51:07.854790Z","shell.execute_reply":"2025-12-30T16:53:40.781359Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # Confusion Matrix\nmodel = skinCancerCNN.to(device)\ny_labels = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n\n# Load the weights from the file saved during training\n# (This requires 'best_skin_cancer_model.pth' to exist in your current folder)\ntry:\n    model.load_state_dict(torch.load('best_skin_cancer_model.pth'))\n    print(\" Successfully loaded the best saved model.\")\nexcept FileNotFoundError:\n    print(\" File not found. Using current model weights instead.\")\n\nmodel.eval() # Set to evaluation mode (Turns off Dropout)\n\n# 2. PREDICTION LOOP: Get all predictions for the validation set\ny_true = []\ny_pred = []\ncorrect = 0\ntotal = 0\n\nprint(\" Processing validation set for Confusion Matrix...\")\n\nwith torch.no_grad(): # Save memory, we don't need gradients here\n    for images, labels, meta_data in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        meta_data = meta_data.to(device)\n        \n        # Forward pass\n        outputs = model(images, meta_data)\n        \n        # Get the class with the highest score\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        test_acc = 100 * correct / total\n        \n        # Move back to CPU and convert to numpy for Sklearn\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(predicted.cpu().numpy())\n\nprint(\" Predictions complete.\")\n\n# 3. COMPUTE & PLOT: Create the Matrix\nprint(f\"---ACCURACY---\\n{test_acc:.2f}% !!\\n\\n---\\n\\n\")\n\ncm = confusion_matrix(y_true, y_pred)\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=y_labels, yticklabels=y_labels)\nplt.xlabel('Predicted Label', fontsize=12)\nplt.ylabel('True Label', fontsize=12)\nplt.title('Confusion Matrix', fontsize=15)\nplt.show()\n\n# 4. REPORT: Print Precision, Recall, and F1-Score\nprint(\"\\n Classification Report:\\n\")\nprint(classification_report(y_true, y_pred, target_names=y_labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T16:53:40.782738Z","iopub.execute_input":"2025-12-30T16:53:40.782945Z","iopub.status.idle":"2025-12-30T16:54:16.956846Z","shell.execute_reply.started":"2025-12-30T16:53:40.782929Z","shell.execute_reply":"2025-12-30T16:54:16.956121Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_tta(model, loader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    \n    # 1. Loop through data\n    with torch.no_grad():\n        for images, labels, meta in tqdm(loader, desc=\"Running TTA\"):\n            images = images.to(device)\n            meta = meta.to(device)\n            \n            # Prediction 1: Original\n            p1 = model(images, meta)\n            \n            # Prediction 2: Horizontal Flip\n            p2 = model(torch.flip(images, [3]), meta) \n            \n            # Prediction 3: Vertical Flip\n            p3 = model(torch.flip(images, [2]), meta)\n            \n            # Average the logits (probabilities)\n            final_pred = (p1 + p2 + p3) / 3.0\n            \n            all_preds.append(final_pred.argmax(dim=1).cpu())\n            all_labels.append(labels.cpu())\n            \n    return torch.cat(all_preds), torch.cat(all_labels)\n\n# Run it\ny_pred_tta, y_true_tta = predict_tta(skinCancerCNN, test_loader)\n\n# Check accuracy\nprint(f\"TTA Accuracy: {(accuracy_score(y_true_tta, y_pred_tta) * 100):.2f}%\")\nprint(classification_report(y_true_tta, y_pred_tta, target_names=label_map.keys()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T16:54:16.958392Z","iopub.execute_input":"2025-12-30T16:54:16.958599Z","iopub.status.idle":"2025-12-30T16:54:35.195353Z","shell.execute_reply.started":"2025-12-30T16:54:16.958582Z","shell.execute_reply":"2025-12-30T16:54:35.194637Z"}},"outputs":[],"execution_count":null}]}