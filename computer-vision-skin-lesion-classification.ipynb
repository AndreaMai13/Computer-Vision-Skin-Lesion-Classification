{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing all the libraries\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport glob\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T15:06:30.268963Z","iopub.execute_input":"2025-12-20T15:06:30.269549Z","iopub.status.idle":"2025-12-20T15:06:30.273993Z","shell.execute_reply.started":"2025-12-20T15:06:30.269523Z","shell.execute_reply":"2025-12-20T15:06:30.273232Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"meta = pd.read_csv(\"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv\")\nunique_lesion_ids = meta['lesion_id'].unique()\n\ntrain_ids, temp_ids = train_test_split(unique_lesion_ids, test_size=0.3)\ntest_ids, validation_ids = train_test_split(temp_ids, test_size=0.5)\n\ntrain_meta = meta[meta['lesion_id'].isin(train_ids)]\ntest_meta = meta[meta['lesion_id'].isin(test_ids)]\nvalidation_meta = meta[meta['lesion_id'].isin(validation_ids)]\n\nprint(f\"train ({100 * len(train_meta) / (len(train_meta) + len(test_meta) + len(validation_meta))}%):\\n{train_meta.head()}\\n\")\nprint(f\"test ({100 * len(test_meta) / (len(train_meta) + len(test_meta) + len(validation_meta))}%):\\n{test_meta.head()}\\n\")\nprint(f\"validation ({100 * len(validation_meta) / (len(train_meta) + len(test_meta) + len(validation_meta))}%):\\n{validation_meta.head()}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T15:06:30.280919Z","iopub.execute_input":"2025-12-20T15:06:30.281456Z","iopub.status.idle":"2025-12-20T15:06:30.337748Z","shell.execute_reply.started":"2025-12-20T15:06:30.281429Z","shell.execute_reply":"2025-12-20T15:06:30.337046Z"}},"outputs":[{"name":"stdout","text":"train (69.59560659011483%):\n     lesion_id      image_id   dx dx_type   age   sex localization\n0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\n\ntest (15.07738392411383%):\n      lesion_id      image_id   dx dx_type   age   sex localization\n6   HAM_0002761  ISIC_0029176  bkl   histo  60.0  male         face\n7   HAM_0002761  ISIC_0029068  bkl   histo  60.0  male         face\n13  HAM_0001949  ISIC_0025767  bkl   histo  70.0  male        trunk\n14  HAM_0001949  ISIC_0032417  bkl   histo  70.0  male        trunk\n21  HAM_0003301  ISIC_0025033  bkl   histo  60.0  male         back\n\nvalidation (15.327009485771343%):\n      lesion_id      image_id   dx dx_type   age     sex     localization\n16  HAM_0001601  ISIC_0025915  bkl   histo  75.0    male  upper extremity\n17  HAM_0001601  ISIC_0031029  bkl   histo  75.0    male  upper extremity\n31  HAM_0005772  ISIC_0031159  bkl   histo  60.0  female             face\n32  HAM_0005772  ISIC_0031017  bkl   histo  60.0  female             face\n51  HAM_0007125  ISIC_0025016  bkl   histo  75.0    male             back\n\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"class SkinCancerDataset(Dataset):\n    def __init__(self, dataframe, dir_part1, dir_part2, transform = None):\n        self.annotation = dataframe\n        self.dir_part1 = dir_part1\n        self.dir_part2 = dir_part2\n        self.transform = transform\n        self.label_map = {\n             'akiec': 0, \n             'bcc': 1, \n             'bkl': 2, \n             'df': 3, \n             'mel': 4, \n             'nv': 5, \n             'vasc': 6}\n\n    def __len__(self):\n        return len(self.annotation)\n\n    def __getitem__(self, index):\n        img_id = self.annotation.iloc[index]['image_id']#ImageID on column 2\n\n        path_part1 = os.path.join(self.dir_part1, img_id + '.jpg')\n        path_part2 = os.path.join(self.dir_part2, img_id + '.jpg')\n        if os.path.exists(path_part1):\n            img_name = path_part1\n        elif os.path.exists(path_part2):\n            img_name = path_part2\n        else:\n            raise FileNotFoundError(f\"Image {img_id} not found in part1 or part2\")\n            \n        image = Image.open(img_name).convert('RGB')\n        \n        label_text = self.annotation.iloc[index]['dx']\n        y_label = torch.tensor(self.label_map[label_text])\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, y_label\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T15:06:30.338970Z","iopub.execute_input":"2025-12-20T15:06:30.339255Z","iopub.status.idle":"2025-12-20T15:06:30.346063Z","shell.execute_reply.started":"2025-12-20T15:06:30.339236Z","shell.execute_reply":"2025-12-20T15:06:30.345291Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"from torchvision import transforms\n\n# Training transforms (Randomness added)\ntrain_transforms = transforms.Compose([\n    transforms.Resize((96, 96)),       \n    transforms.RandomHorizontalFlip(),   \n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(20),       \n    transforms.ToTensor(),               \n    transforms.Normalize(                # Standardizes to ImageNet distribution\n        mean=[0.485, 0.456, 0.406], \n        std=[0.229, 0.224, 0.225]\n    )\n])\n\n# Validation transforms (No Randomness, just resizing)\nval_transforms = transforms.Compose([\n    transforms.Resize((96, 96)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T15:06:30.346757Z","iopub.execute_input":"2025-12-20T15:06:30.347032Z","iopub.status.idle":"2025-12-20T15:06:30.363341Z","shell.execute_reply.started":"2025-12-20T15:06:30.347015Z","shell.execute_reply":"2025-12-20T15:06:30.362578Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"def get_device():\n    if torch.cuda.is_available():\n        print(f\"‚úÖ GPU Detected: {torch.cuda.get_device_name(0)}\")\n        return torch.device(\"cuda\")\n    \n    elif torch.backends.mps.is_available():\n        print(\"‚úÖ Apple Silicon GPU Detected\")\n        return torch.device(\"mps\")\n    \n    else:\n        print(\"‚ö†Ô∏è No GPU detected. Training will be slow.\")\n        return torch.device(\"cpu\")\n\n\ndevice = get_device()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T15:06:30.364615Z","iopub.execute_input":"2025-12-20T15:06:30.364946Z","iopub.status.idle":"2025-12-20T15:06:30.378027Z","shell.execute_reply.started":"2025-12-20T15:06:30.364924Z","shell.execute_reply":"2025-12-20T15:06:30.377385Z"}},"outputs":[{"name":"stdout","text":"‚úÖ GPU Detected: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"class DoubleConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n\n    def forward(self, x):\n        x = F.leaky_relu(self.bn1(self.conv1(x)))\n        x = F.leaky_relu(self.bn2(self.conv2(x)))\n        x = self.pool(x)\n        return x\n        \n\nclass SkinCancerCNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        #feature extraction\n        self.block1 = DoubleConvBlock(3, 32)\n        self.block2 = DoubleConvBlock(32, 64)\n        self.block3 = DoubleConvBlock(64, 128)\n        self.block4 = DoubleConvBlock(128, 256)\n        \n        self.flatten_size = 256 * 6 * 6\n        \n        # First fully connected layer\n        self.fc1 = nn.Linear(self.flatten_size, 512)\n        self.dropout = nn.Dropout(0.2)\n        # Second fully connected layer \n        self.fc2 = nn.Linear(512, 128)\n        \n        #third fully connected layer that outputs our 10 labels\n        self.fc3 = nn.Linear(128, 7)\n\n    def forward(self, x):\n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        x = self.block4(x)\n        \n        #flatten the data\n        x = x.view(-1, self.flatten_size)\n        #FC layers\n        x = F.leaky_relu(self.fc1(x))\n        x = self.dropout(x)\n        x = F.leaky_relu(self.fc2(x))\n        x = self.dropout(x)\n        x = self.fc3(x)\n\n        return x\n\nskinCancerCNN = SkinCancerCNN()\nprint(skinCancerCNN)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T15:06:30.379112Z","iopub.execute_input":"2025-12-20T15:06:30.379329Z","iopub.status.idle":"2025-12-20T15:06:30.439228Z","shell.execute_reply.started":"2025-12-20T15:06:30.379313Z","shell.execute_reply":"2025-12-20T15:06:30.438387Z"}},"outputs":[{"name":"stdout","text":"SkinCancerCNN(\n  (block1): DoubleConvBlock(\n    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (block2): DoubleConvBlock(\n    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (block3): DoubleConvBlock(\n    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (block4): DoubleConvBlock(\n    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc1): Linear(in_features=9216, out_features=512, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n  (fc2): Linear(in_features=512, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=7, bias=True)\n)\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"labels = meta['dx'].unique()\nlabels, counts = np.unique(meta['dx'], return_counts=True)\nweights = 1.0 / counts \nweights = weights / weights.sum() * len(counts)\nweights = torch.tensor(weights, dtype=torch.float)\n\nweights = weights.to(device)\n\nprint(labels, counts, weights)\n\ncriterion = nn.CrossEntropyLoss(weight=weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T15:06:30.440054Z","iopub.execute_input":"2025-12-20T15:06:30.440235Z","iopub.status.idle":"2025-12-20T15:06:30.453420Z","shell.execute_reply.started":"2025-12-20T15:06:30.440219Z","shell.execute_reply":"2025-12-20T15:06:30.452533Z"}},"outputs":[{"name":"stdout","text":"['akiec' 'bcc' 'bkl' 'df' 'mel' 'nv' 'vasc'] [ 327  514 1099  115 1113 6705  142] tensor([0.9431, 0.6000, 0.2806, 2.6816, 0.2771, 0.0460, 2.1717],\n       device='cuda:0')\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"learning_rate = 0.0001\n\noptimizer = optim.Adam(skinCancerCNN.parameters(), learning_rate)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T15:06:30.455134Z","iopub.execute_input":"2025-12-20T15:06:30.455368Z","iopub.status.idle":"2025-12-20T15:06:30.466755Z","shell.execute_reply.started":"2025-12-20T15:06:30.455352Z","shell.execute_reply":"2025-12-20T15:06:30.466186Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"# Define your paths (Adjust these to match your specific Kaggle input structure)\ndir_1 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1/\"\ndir_2 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2/\"\n\n# Create Datasets passing BOTH directories\ntrain_dataset = SkinCancerDataset(train_meta, dir_1, dir_2, transform=train_transforms)\nval_dataset = SkinCancerDataset(validation_meta, dir_1, dir_2, transform=val_transforms)\ntest_dataset = SkinCancerDataset(test_meta, dir_1, dir_2, transform=val_transforms)\n\n# Create DataLoaders\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T15:06:30.467509Z","iopub.execute_input":"2025-12-20T15:06:30.467683Z","iopub.status.idle":"2025-12-20T15:06:30.476072Z","shell.execute_reply.started":"2025-12-20T15:06:30.467669Z","shell.execute_reply":"2025-12-20T15:06:30.475400Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"import time\nfrom tqdm import tqdm # Library for progress bars\nimport matplotlib.pyplot as plt\n\n# ==========================================\n# CONFIGURATION\n# ==========================================\npatience = 10        # How many epochs to wait before stopping if no improvement\nmin_delta = 0.0005   # Minimum change to qualify as an improvement\nearly_stop_counter = 0\nbest_val_loss = float('inf')\nnum_epochs = 40\n\n# Move model to device\nmodel = skinCancerCNN.to(device)\n\n# History storage\nhistory = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n\nprint(f\"üöÄ Starting training on {device} with Early Stopping...\")\n\n# ==========================================\n# TRAINING LOOP\n# ==========================================\nfor epoch in range(num_epochs):\n    \n    # --- 1. Training Phase ---\n    model.train()\n    running_loss = 0.0\n    \n    # Wrap train_loader with tqdm for a progress bar\n    # 'desc' sets the text before the bar\n    loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\", leave=False)\n    \n    for images, labels in loop:\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * images.size(0)\n        \n        # Update progress bar with current loss\n        loop.set_postfix(loss=loss.item())\n\n    epoch_loss = running_loss / len(train_loader.dataset)\n    history['train_loss'].append(epoch_loss)\n\n    # --- 2. Validation Phase ---\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item() * images.size(0)\n            \n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n    epoch_val_loss = val_loss / len(val_loader.dataset)\n    epoch_acc = 100 * correct / total\n    \n    history['val_loss'].append(epoch_val_loss)\n    history['val_acc'].append(epoch_acc)\n\n    # Print Clean Stats\n    print(f\"Epoch [{epoch+1}/{num_epochs}]  \"\n          f\"Train Loss: {epoch_loss:.4f} | \"\n          f\"Val Loss: {epoch_val_loss:.4f} | \"\n          f\"Val Acc: {epoch_acc:.2f}%\")\n\n    # ==========================================\n    # EARLY STOPPING LOGIC\n    # ==========================================\n    # Check if this validation loss is the best we've seen\n    if epoch_val_loss < (best_val_loss - min_delta):\n        best_val_loss = epoch_val_loss\n        early_stop_counter = 0 # Reset counter\n        torch.save(model.state_dict(), 'best_skin_cancer_model.pth')\n        print(f\"   ‚úÖ Validation Loss Improved. Model Saved.\")\n    else:\n        early_stop_counter += 1\n        print(f\"   ‚ö†Ô∏è No improvement for {early_stop_counter}/{patience} epochs.\")\n        \n    if early_stop_counter >= patience:\n        print(f\"\\nüõë Early Stopping Triggered! Training stopped at Epoch {epoch+1}.\")\n        break\n\nprint(\"Training Finished.\")\n\n# ==========================================\n# VISUALIZATION\n# ==========================================\ndef plot_training_history(history):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n\n    # Plot Loss\n    ax1.plot(history['train_loss'], label='Train Loss')\n    ax1.plot(history['val_loss'], label='Val Loss')\n    ax1.set_title('Loss History')\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Loss')\n    ax1.legend()\n    ax1.grid(True)\n\n    # Plot Accuracy\n    ax2.plot(history['val_acc'], label='Val Accuracy', color='green')\n    ax2.set_title('Validation Accuracy')\n    ax2.set_xlabel('Epoch')\n    ax2.set_ylabel('Accuracy (%)')\n    ax2.legend()\n    ax2.grid(True)\n\n    plt.show()\n\n# Run the plot\nplot_training_history(history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T15:06:30.476796Z","iopub.execute_input":"2025-12-20T15:06:30.477017Z","iopub.status.idle":"2025-12-20T15:06:41.384929Z","shell.execute_reply.started":"2025-12-20T15:06:30.477000Z","shell.execute_reply":"2025-12-20T15:06:41.383759Z"}},"outputs":[{"name":"stdout","text":"üöÄ Starting training on cuda with Early Stopping...\n","output_type":"stream"},{"name":"stderr","text":"                                                                         \r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2764917175.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch [{epoch+1}/{num_epochs}]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/2639582747.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Image {img_id} not found in part1 or part2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mlabel_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    984\u001b[0m             \u001b[0mdeprecate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"transparency\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":58}]}